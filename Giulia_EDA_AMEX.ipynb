{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "Giulia_EDA_AMEX.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "gpuClass": "standard"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/giuliaguglielmi123/Copulas/blob/main/Giulia_EDA_AMEX.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.002235,
          "end_time": "2022-06-19T23:15:37.774992",
          "exception": false,
          "start_time": "2022-06-19T23:15:37.772757",
          "status": "completed"
        },
        "tags": [],
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "ovmytNYZW7iu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================\n",
        "# Library\n",
        "# ====================================================\n",
        "import gc\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import scipy as sp\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.width', 1000)\n",
        "from tqdm.auto import tqdm\n",
        "import itertools"
      ],
      "metadata": {
        "id": "g-72yoLoXFAg"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gc\n",
        "\n",
        "from configparser import ConfigParser\n",
        "from configparser import ExtendedInterpolation\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ],
      "metadata": {
        "id": "PJCUtVMwXN3L"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVnKsux9XPky",
        "outputId": "838ff9c8-020f-4e3f-c893-39ccaa1d1b80"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = ConfigParser(interpolation=ExtendedInterpolation())\n",
        "config.read(\"/content/drive/MyDrive/GitHub/Kaggle_American_Express_Default_Prediction/config/paths.ini\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZlTcefvXc46",
        "outputId": "14fde816-a63e-41d8-cf9b-8af67d37531c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/GitHub/Kaggle_American_Express_Default_Prediction/config/paths.ini']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(config[\"paths\"][\"root_dir\"])"
      ],
      "metadata": {
        "id": "MGJYZX5iXUoj"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_feather(config[\"paths\"][\"path_data\"] + \"raw/train_data.ftr\")"
      ],
      "metadata": {
        "id": "HEeni8UOL-TF"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "73LHq8GSMB9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================\n",
        "# Read & preprocess data and save it to disk\n",
        "# ====================================================\n",
        "def read_preprocess_data():\n",
        "    train = pd.read_feather(config[\"paths\"][\"path_data\"] + \"raw/train_data.ftr\")\n",
        "    features = train.drop(['customer_ID', 'S_2'], axis = 1).columns.to_list()\n",
        "    cat_features = [\n",
        "        \"B_30\",\n",
        "        \"B_38\",\n",
        "        \"D_114\",\n",
        "        \"D_116\",\n",
        "        \"D_117\",\n",
        "        \"D_120\",\n",
        "        \"D_126\",\n",
        "        \"D_63\",\n",
        "        \"D_64\",\n",
        "        \"D_66\",\n",
        "        \"D_68\",\n",
        "    ]\n",
        "    num_features = [col for col in features if col not in cat_features]\n",
        "    \n",
        "    # Train FE\n",
        "    print('Starting train feature extraction')\n",
        "    train_num_agg = train.groupby(\"customer_ID\")[num_features].agg(['first', 'mean', 'std', 'min', 'max', 'last'])\n",
        "    train_num_agg.columns = ['_'.join(x) for x in train_num_agg.columns]\n",
        "    train_num_agg.reset_index(inplace = True)\n",
        "\n",
        "    # Lag Features\n",
        "    for col in train_num_agg:\n",
        "        if 'last' in col and col.replace('last', 'first') in train_num_agg:\n",
        "            train_num_agg[col + '_lag_sub'] = train_num_agg[col] - train_num_agg[col.replace('last', 'first')]\n",
        "            train_num_agg[col + '_lag_div'] = train_num_agg[col] / train_num_agg[col.replace('last', 'first')]\n",
        "\n",
        "    train_cat_agg = train.groupby(\"customer_ID\")[cat_features].agg(['count', 'first', 'last', 'nunique'])\n",
        "    train_cat_agg.columns = ['_'.join(x) for x in train_cat_agg.columns]\n",
        "    train_cat_agg.reset_index(inplace = True)\n",
        "    \n",
        "    train_labels = pd.read_csv(config[\"paths\"][\"path_data\"] + \"raw/train_labels.csv\")\n",
        "    train = train_num_agg.merge(train_cat_agg, how = 'inner', on = 'customer_ID').merge(train_labels, how = 'inner', on = 'customer_ID')\n",
        "    print('Train shape: ', train.shape)    \n",
        "    del train_num_agg, train_cat_agg        \n",
        "    gc.collect()\n",
        "\n",
        "    train.to_pickle(config[\"paths\"][\"path_data\"] + \"processed/train_data_agg.pkl\")\n",
        "\n",
        "    del train\n",
        "    \n",
        "    \n",
        "    # Test FE\n",
        "    test = pd.read_feather(config[\"paths\"][\"path_data\"] + \"raw/test_data.ftr\")\n",
        "    print('Starting test feature extraction')\n",
        "    test_num_agg = test.groupby(\"customer_ID\")[num_features].agg(['first', 'mean', 'std', 'min', 'max', 'last'])\n",
        "    test_num_agg.columns = ['_'.join(x) for x in test_num_agg.columns]\n",
        "    test_num_agg.reset_index(inplace = True)\n",
        "\n",
        "    # Lag Features\n",
        "    for col in test_num_agg:\n",
        "        if 'last' in col and col.replace('last', 'first') in test_num_agg:\n",
        "            test_num_agg[col + '_lag_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
        "            test_num_agg[col + '_lag_div'] = test_num_agg[col] / test_num_agg[col.replace('last', 'first')]\n",
        "\n",
        "    test_cat_agg = test.groupby(\"customer_ID\")[cat_features].agg(['count', 'first', 'last', 'nunique'])\n",
        "    test_cat_agg.columns = ['_'.join(x) for x in test_cat_agg.columns]\n",
        "    test_cat_agg.reset_index(inplace = True)\n",
        "    \n",
        "    test = test_num_agg.merge(test_cat_agg, how = 'inner', on = 'customer_ID')\n",
        "    print('Test shape: ', test.shape)\n",
        "    del test_num_agg, test_cat_agg\n",
        "    gc.collect()\n",
        "    \n",
        "    \n",
        "    # Save files to disk\n",
        "    \n",
        "    test.to_pickle(config[\"paths\"][\"path_data\"] + \"processed/test_data_agg.pkl\")\n",
        "    \n",
        "# Read & Preprocess Data\n",
        "read_preprocess_data()"
      ],
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "papermill": {
          "duration": 0.16385,
          "end_time": "2022-06-19T23:15:37.941388",
          "exception": false,
          "start_time": "2022-06-19T23:15:37.777538",
          "status": "completed"
        },
        "tags": [],
        "pycharm": {
          "name": "#%%\n"
        },
        "execution": {
          "iopub.status.busy": "2022-07-03T16:36:49.935597Z",
          "iopub.execute_input": "2022-07-03T16:36:49.936366Z",
          "iopub.status.idle": "2022-07-03T16:36:50.113435Z",
          "shell.execute_reply.started": "2022-07-03T16:36:49.936242Z",
          "shell.execute_reply": "2022-07-03T16:36:50.112486Z"
        },
        "trusted": true,
        "id": "5UkRNR9tW7iv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f80c5d10-4162-48f1-9c62-f06ad06e15c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting train feature extraction\n",
            "Train shape:  (458913, 1462)\n",
            "Starting test feature extraction\n",
            "Test shape:  (924621, 1461)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training & Inference"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.002398,
          "end_time": "2022-06-19T23:15:37.946621",
          "exception": false,
          "start_time": "2022-06-19T23:15:37.944223",
          "status": "completed"
        },
        "tags": [],
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "OuqV-jZiW7iy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================\n",
        "# Library\n",
        "# ====================================================\n",
        "import os\n",
        "import gc\n",
        "import joblib\n",
        "import random\n",
        "import warnings\n",
        "import itertools\n",
        "import scipy as sp\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "warnings.filterwarnings('ignore')\n",
        "from itertools import combinations\n",
        "pd.set_option('display.width', 1000)\n",
        "pd.set_option('display.max_rows', 500)\n",
        "from catboost import CatBoostClassifier\n",
        "pd.set_option('display.max_columns', 500)\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "\n",
        "class CFG:\n",
        "    input_dir = '../input/amex-fe/'\n",
        "    seed = 42\n",
        "    n_folds = 5\n",
        "    target = 'target'\n",
        "\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "\n",
        "def read_data():\n",
        "    train = pd.read_parquet(CFG.input_dir + 'train_fe_plus_plus.parquet')\n",
        "    test = pd.read_parquet(CFG.input_dir + 'test_fe_plus_plus.parquet')\n",
        "    return train, test\n",
        "\n",
        "def amex_metric(y_true, y_pred):\n",
        "    labels = np.transpose(np.array([y_true, y_pred]))\n",
        "    labels = labels[labels[:, 1].argsort()[::-1]]\n",
        "    weights = np.where(labels[:,0]==0, 20, 1)\n",
        "    cut_vals = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n",
        "    top_four = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n",
        "    gini = [0,0]\n",
        "    for i in [1,0]:\n",
        "        labels = np.transpose(np.array([y_true, y_pred]))\n",
        "        labels = labels[labels[:, i].argsort()[::-1]]\n",
        "        weight = np.where(labels[:,0]==0, 20, 1)\n",
        "        weight_random = np.cumsum(weight / np.sum(weight))\n",
        "        total_pos = np.sum(labels[:, 0] *  weight)\n",
        "        cum_pos_found = np.cumsum(labels[:, 0] * weight)\n",
        "        lorentz = cum_pos_found / total_pos\n",
        "        gini[i] = np.sum((lorentz - weight_random) * weight)\n",
        "    return 0.5 * (gini[1]/gini[0] + top_four)\n",
        "\n",
        "def amex_metric_np(preds, target):\n",
        "    indices = np.argsort(preds)[::-1]\n",
        "    preds, target = preds[indices], target[indices]\n",
        "    weight = 20.0 - target * 19.0\n",
        "    cum_norm_weight = (weight / weight.sum()).cumsum()\n",
        "    four_pct_mask = cum_norm_weight <= 0.04\n",
        "    d = np.sum(target[four_pct_mask]) / np.sum(target)\n",
        "    weighted_target = target * weight\n",
        "    lorentz = (weighted_target / weighted_target.sum()).cumsum()\n",
        "    gini = ((lorentz - cum_norm_weight) * weight).sum()\n",
        "    n_pos = np.sum(target)\n",
        "    n_neg = target.shape[0] - n_pos\n",
        "    gini_max = 10 * n_neg * (n_pos + 20 * n_neg - 19) / (n_pos + 20 * n_neg)\n",
        "    g = gini / gini_max\n",
        "    return 0.5 * (g + d)"
      ],
      "metadata": {
        "papermill": {
          "duration": 1.91354,
          "end_time": "2022-06-19T23:15:39.862701",
          "exception": false,
          "start_time": "2022-06-19T23:15:37.949161",
          "status": "completed"
        },
        "tags": [],
        "pycharm": {
          "name": "#%%\n"
        },
        "execution": {
          "iopub.status.busy": "2022-07-03T16:36:50.115074Z",
          "iopub.execute_input": "2022-07-03T16:36:50.115416Z",
          "iopub.status.idle": "2022-07-03T16:36:52.698333Z",
          "shell.execute_reply.started": "2022-07-03T16:36:50.115388Z",
          "shell.execute_reply": "2022-07-03T16:36:52.697548Z"
        },
        "trusted": true,
        "id": "36GP65yRW7iz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training LightGBM (DART) Model\n",
        "\n",
        "- Final predictions output uploaded as a public dataset. "
      ],
      "metadata": {
        "id": "XvEun4kQW7i0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lgb_amex_metric(y_pred, y_true):\n",
        "    y_true = y_true.get_label()\n",
        "    return 'amex_metric', amex_metric(y_true, y_pred), True\n",
        "\n",
        "def train_and_evaluate(train, test):\n",
        "    # Label encode categorical features\n",
        "    cat_features = [\n",
        "        \"B_30\",\n",
        "        \"B_38\",\n",
        "        \"D_114\",\n",
        "        \"D_116\",\n",
        "        \"D_117\",\n",
        "        \"D_120\",\n",
        "        \"D_126\",\n",
        "        \"D_63\",\n",
        "        \"D_64\",\n",
        "        \"D_66\",\n",
        "        \"D_68\"\n",
        "    ]\n",
        "    cat_features = [f\"{cf}_last\" for cf in cat_features]\n",
        "    for cat_col in cat_features:\n",
        "        encoder = LabelEncoder()\n",
        "        train[cat_col] = encoder.fit_transform(train[cat_col])\n",
        "        test[cat_col] = encoder.transform(test[cat_col])\n",
        "    # Round last float features to 2 decimal place\n",
        "    num_cols = list(train.dtypes[(train.dtypes == 'float32') | (train.dtypes == 'float64')].index)\n",
        "    num_cols = [col for col in num_cols if 'last' in col]\n",
        "    for col in num_cols:\n",
        "        train[col + '_round2'] = train[col].round(2)\n",
        "        test[col + '_round2'] = test[col].round(2)\n",
        "    # Get feature list\n",
        "    features = [col for col in train.columns if col not in ['customer_ID', CFG.target]]\n",
        "    params = {\n",
        "        'objective': 'binary',\n",
        "        'metric': \"binary_logloss\",\n",
        "        'boosting': 'dart',\n",
        "        'seed': CFG.seed,\n",
        "        'num_leaves': 100,\n",
        "        'learning_rate': 0.01,\n",
        "        'feature_fraction': 0.20,\n",
        "        'bagging_freq': 10,\n",
        "        'bagging_fraction': 0.50,\n",
        "        'n_jobs': -1,\n",
        "        'lambda_l2': 2,\n",
        "        'min_data_in_leaf': 40\n",
        "        }\n",
        "    # Create a numpy array to store test predictions\n",
        "    test_predictions = np.zeros(len(test))\n",
        "    # Create a numpy array to store out of folds predictions\n",
        "    oof_predictions = np.zeros(len(train))\n",
        "    kfold = StratifiedKFold(n_splits = CFG.n_folds, shuffle = True, random_state = CFG.seed)\n",
        "    for fold, (trn_ind, val_ind) in enumerate(kfold.split(train, train[CFG.target])):\n",
        "        print(' ')\n",
        "        print('-'*50)\n",
        "        print(f'Training fold {fold} with {len(features)} features...')\n",
        "        x_train, x_val = train[features].iloc[trn_ind], train[features].iloc[val_ind]\n",
        "        y_train, y_val = train[CFG.target].iloc[trn_ind], train[CFG.target].iloc[val_ind]\n",
        "        lgb_train = lgb.Dataset(x_train, y_train, categorical_feature = cat_features)\n",
        "        lgb_valid = lgb.Dataset(x_val, y_val, categorical_feature = cat_features)\n",
        "        model = lgb.train(\n",
        "            params = params,\n",
        "            train_set = lgb_train,\n",
        "            num_boost_round = 10500,\n",
        "            valid_sets = [lgb_train, lgb_valid],\n",
        "            early_stopping_rounds = 100,\n",
        "            verbose_eval = 500,\n",
        "            feval = lgb_amex_metric\n",
        "            )\n",
        "        # Save best model\n",
        "        joblib.dump(model, f'lgbm_fold{fold}_seed{CFG.seed}.pkl')\n",
        "        # Predict validation\n",
        "        val_pred = model.predict(x_val)\n",
        "        # Add to out of folds array\n",
        "        oof_predictions[val_ind] = val_pred\n",
        "        # Predict the test set\n",
        "        test_pred = model.predict(test[features])\n",
        "        test_predictions += test_pred / CFG.n_folds\n",
        "        # Compute fold metric\n",
        "        score = amex_metric(y_val, val_pred)\n",
        "        print(f'Our fold {fold} CV score is {score}')\n",
        "        del x_train, x_val, y_train, y_val, lgb_train, lgb_valid\n",
        "        gc.collect()\n",
        "    # Compute out of folds metric\n",
        "    score = amex_metric(train[CFG.target], oof_predictions)\n",
        "    print(f'Our out of folds CV score is {score}')\n",
        "    # Create a dataframe to store out of folds predictions\n",
        "    oof_df = pd.DataFrame({'customer_ID': train['customer_ID'], 'target': train[CFG.target], 'prediction': oof_predictions})\n",
        "    oof_df.to_csv(f'oof_lgbm_baseline_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n",
        "    # Create a dataframe to store test prediction\n",
        "    test_df = pd.DataFrame({'customer_ID': test['customer_ID'], 'prediction': test_predictions})\n",
        "    test_df.to_csv(f'test_lgbm_baseline_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n",
        "\n",
        "# seed_everything(CFG.seed)\n",
        "# train, test = read_data()\n",
        "# train_and_evaluate(train, test)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2022-07-03T16:36:52.700595Z",
          "iopub.execute_input": "2022-07-03T16:36:52.701018Z",
          "iopub.status.idle": "2022-07-03T16:36:52.731615Z",
          "shell.execute_reply.started": "2022-07-03T16:36:52.700987Z",
          "shell.execute_reply": "2022-07-03T16:36:52.730798Z"
        },
        "trusted": true,
        "id": "nlsUjEpgW7i1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction\n",
        "\n",
        "- Replace / comment-out this to use your own predictions from the model in the above cell."
      ],
      "metadata": {
        "papermill": {
          "duration": 0.00263,
          "end_time": "2022-06-19T23:15:39.870669",
          "exception": false,
          "start_time": "2022-06-19T23:15:39.868039",
          "status": "completed"
        },
        "tags": [],
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "aty2sqtoW7i2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "df_1 = pd.read_csv('../input/amex-predictions/test_lgbm_baseline_5fold_seed42.csv')\n",
        "df_1.to_csv('submission.csv', index=False)"
      ],
      "metadata": {
        "papermill": {
          "duration": 7.116467,
          "end_time": "2022-06-19T23:15:46.98989",
          "exception": false,
          "start_time": "2022-06-19T23:15:39.873423",
          "status": "completed"
        },
        "tags": [],
        "pycharm": {
          "name": "#%%\n"
        },
        "execution": {
          "iopub.status.busy": "2022-07-03T16:36:52.796711Z",
          "iopub.execute_input": "2022-07-03T16:36:52.797315Z",
          "iopub.status.idle": "2022-07-03T16:37:04.221485Z",
          "shell.execute_reply.started": "2022-07-03T16:36:52.797274Z",
          "shell.execute_reply": "2022-07-03T16:37:04.220504Z"
        },
        "trusted": true,
        "id": "ktIHeGAvW7i3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}